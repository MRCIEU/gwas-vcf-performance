---
title: "Prepare data for quering"
author: "Matt Lyon"
date: "2020-08-12"
params:
    n_sim: 5
    n_variants: 2500000
    n_gwas: 1
    filepath: NA
---

### Set params

```{r}
Sys.setenv(n_sim=params$n_sim, n_gwas=params$n_gwas, file=params$filepath, n_variants=format(params$n_variants, scientific = FALSE))
```

### Randomly select n variants

Subsample the GWAS-VCF to obtain n variants

```{bash}
echo "$n_variants"
echo "$file"
# select header
bcftools view -h "$file" > /data/tmp.vcf
# select body, randomly sort and select n_variants
bcftools view -H "$file" | shuf | head -n "$n_variants" >> /data/tmp.vcf
# sort and compress
bcftools sort /data/tmp.vcf -O z -o /data/tmp.vcf.gz
# index
bcftools index -t /data/tmp.vcf.gz
```

Duplicate data to produce multisample GWAS-VCF files

```{bash}
for i in $(seq 1 $n_gwas); do
    cp /data/tmp.vcf.gz /data/"$i"_sampled.vcf.gz
    cp /data/tmp.vcf.gz.tbi /data/"$i"_sampled.vcf.gz.tbi
done
```

### Merge GWAS-VCF

Merge multiple GWAS-VCF files into single file if multiple are present

```{bash}
if [ $(ls /data/*_sampled.vcf.gz | wc -l) -gt 1 ]; then
    bcftools merge \
    --force-samples \
    -O z \
    -o /data/gwas.vcf.gz \
    $(ls /data/*_sampled.vcf.gz)
else
    mv /data/*_sampled.vcf.gz /data/gwas.vcf.gz
fi

bcftools index /data/gwas.vcf.gz
```

### Index on rsID

[rsidx](https://github.com/bioforensics/rsidx) is an excellent tool for indexing on VCF ID. This is made possible by extracting rsID and chromosome position to an SQLite database which is later queried to obtain the variant locus for extraction using tabix.

```{bash}
rsidx index -f \
/data/gwas.vcf.gz \
/data/gwas.vcf.gz.rsidx
```

### Create uncompressed VCF & index

Uncompress the file to see what the performance impact is later.

```{bash}
zcat /data/gwas.vcf.gz > /data/gwas.vcf
/usr/bin/gatk-4.1.5.0/gatk \
IndexFeatureFile \
-I /data/gwas.vcf
```

### Create compressed BCF & index

Convert to BCF to see what the performance impact is later.

```{bash}
bcftools view \
-O b \
-o /data/gwas.bcf \
/data/gwas.vcf.gz

bcftools index /data/gwas.bcf
```

### Prepare tabular extract for performance comparisons

Create extract of VCF to text for performance comparisons later

```{bash}
echo -e "CHROM\tPOS\tREF\tALT\tID\tES\tSE\tLP\tAF\tSS" > /data/gwas.txt
bcftools query \
-f '%CHROM\t%POS\t%REF\t%ALT\t%ID[\t%ES\t%SE\t%LP\t%AF\t%SS]\n' \
/data/gwas.vcf.gz >> /data/gwas.txt
gzip -c /data/gwas.txt > /data/gwas.txt.gz
```

### Define queries

```{r}
library('data.table')
set.seed(12345)
options(scipen=999)

# read in tab GWAS
gwas <- fread("/data/gwas.txt")

# subsample variants
s <- gwas[sample(nrow(gwas), params$n_sim),]

# write out list of rsid for querying later
write.table(s$ID, sep="\t", row.names=F, quote=F, col.names=F, file="/data/rsid.txt")

# write out list of chrom pos for querying later
write.table(s[,c("CHROM", "POS")], sep="\t", row.names=F, quote=F, col.names=F, file="/data/chrpos.txt")

# write out list of 1Mb intervals and count number of variants for querying later
s$start <- s$POS - 500000
s$end <- s$POS + 500000
s$interval_count <- apply(s, 1, function(row){ length(which(gwas$CHROM == row[['CHROM']] & gwas$POS >= as.numeric(row[['start']]) & gwas$POS <= as.numeric(row[['end']]))) })
write.table(s[,c("CHROM", "start", "end", "interval_count")], sep="\t", row.names=F, quote=F, col.names=F, file="/data/intervals.txt")

# write out pval thresholds & counts for querying later
gwas$LP <- as.numeric(gwas$LP)

## define pval thresholds
thresholds <- seq(0.00000005, 1, 1/params$n_sim)
thresholds <- -log10(thresholds)

## round to avoid float imprecision issues
thresholds <- round(thresholds, 4)

## count records
counts <- sapply(thresholds, function (threshold) {sum(gwas$LP > threshold, na.rm = T)})
write.table(data.frame(thresholds=thresholds, counts=counts), sep="\t", row.names=F, quote=F, col.names=F, file="/data/pval.txt")

message(paste("Total number of variants in GWAS:", nrow(gwas)))
```
